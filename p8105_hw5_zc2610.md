p8105_hw5_zc2610
================
Zuoqiao Cui
2022-11-04

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(ggplot2)
```

# Problem 2

``` r
homicide_data_df = read_csv("./data/homicide-data.csv") %>% 
janitor::clean_names()
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Raw data decription:

1.  This dataset contains 52179 observations and 12 variables.

2.  Variables include : uid, reported_date, victim_last, victim_first,
    victim_race, victim_age, victim_sex, city, state, lat, lon,
    disposition

Create a new variable “city_state” to combine city and state columns

``` r
homicide_data_df = homicide_data_df %>% 
  mutate(
    city_state = str_c(city, state, sep = ",")
  ) %>% 
  select(-city,-state)
```

Create a new variable to show if this homicide has been solved

``` r
homicide_data_df = homicide_data_df %>% 
  mutate(
    whether_solved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  )
```

Obtain the total number of homicides and the number of unsolved
homicides

``` r
num_of_homicide_df = homicide_data_df %>% 
  group_by(city_state) %>% 
  summarise(
    homicide_total = n(),
    homicide_unsolved = sum(whether_solved == "unsolved")
  ) 
num_of_homicide_df
```

    ## # A tibble: 51 × 3
    ##    city_state     homicide_total homicide_unsolved
    ##    <chr>                   <int>             <int>
    ##  1 Albuquerque,NM            378               146
    ##  2 Atlanta,GA                973               373
    ##  3 Baltimore,MD             2827              1825
    ##  4 Baton Rouge,LA            424               196
    ##  5 Birmingham,AL             800               347
    ##  6 Boston,MA                 614               310
    ##  7 Buffalo,NY                521               319
    ##  8 Charlotte,NC              687               206
    ##  9 Chicago,IL               5535              4073
    ## 10 Cincinnati,OH             694               309
    ## # … with 41 more rows

1.  Estimate the proportion of homicides that are unsolved in
    Baltimore,MD and save the output of prop.test

2.  Pull the estimated proportion and confidence intervals from the
    resulting tidy dataframe

``` r
Baltimore_unsolved_homicide_df = num_of_homicide_df %>% 
  filter(city_state == "Baltimore,MD")
  x = Baltimore_unsolved_homicide_df %>%
    pull(homicide_unsolved)  
  n = Baltimore_unsolved_homicide_df %>%
    pull(homicide_total)
result_df = prop.test(x,n) %>% 
  broom::tidy()
result_df
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method        alter…¹
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>         <chr>  
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample pro… two.si…
    ## # … with abbreviated variable name ¹​alternative

``` r
# pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
result_df %>% 
  select(estimate,conf.low,conf.high)
```

    ## # A tibble: 1 × 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

1.  Estimate the proportion of homicides that are unsolved in each city

2.  Tidy hypothesis outputs of the dataframe

3.  Create a new dataframe containing variables in num_of_homicide_df
    dataframe and two new variables: City_unsolved_homicide and
    Tidy_city_unsolved_homicide which include lists of hypothesis
    outputs

4.  Create a tidy dataframe with estimated proportions and CIs for each
    cit

``` r
  x = num_of_homicide_df %>%
  pull(homicide_unsolved) 
  n = num_of_homicide_df %>% 
  pull(homicide_total) 
  hypothesis_result_df = num_of_homicide_df %>% 
    mutate(
      City_unsolved_homicide =  map2(x,n,prop.test),
       # Tidy hypothesis outputs of the dataframe
      Tidy_city_unsolved_homicide = map(City_unsolved_homicide, broom::tidy)
    ) %>% 
    select(city_state,Tidy_city_unsolved_homicide)
```

    ## Warning in .f(.x[[i]], .y[[i]], ...): Chi-squared approximation may be incorrect

``` r
    tidy_hypothesis_result_df = unnest(hypothesis_result_df) %>% 
    select(city_state,estimate,conf.low,conf.high)
```

    ## Warning: `cols` is now required when using unnest().
    ## Please use `cols = c(Tidy_city_unsolved_homicide)`

``` r
    tidy_hypothesis_result_df
```

    ## # A tibble: 51 × 4
    ##    city_state     estimate conf.low conf.high
    ##    <chr>             <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque,NM    0.386    0.337     0.438
    ##  2 Atlanta,GA        0.383    0.353     0.415
    ##  3 Baltimore,MD      0.646    0.628     0.663
    ##  4 Baton Rouge,LA    0.462    0.414     0.511
    ##  5 Birmingham,AL     0.434    0.399     0.469
    ##  6 Boston,MA         0.505    0.465     0.545
    ##  7 Buffalo,NY        0.612    0.569     0.654
    ##  8 Charlotte,NC      0.300    0.266     0.336
    ##  9 Chicago,IL        0.736    0.724     0.747
    ## 10 Cincinnati,OH     0.445    0.408     0.483
    ## # … with 41 more rows

1.  Create a plot that shows the estimates and CIs for each city

2.  Organize cities according to the proportion of unsolved homicides
    and save the plot to a file folder.

``` r
tidy_hypothesis_result_df = tidy_hypothesis_result_df %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(x = city_state,y = estimate,color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymax = conf.high,ymin = conf.low)) +
  labs(
    title = "Estimated proportions and CIs of unsolved homicides in each city",
     x = "City & State",
     y = "Estimated Proportion",
    caption = "Data from [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license]"
  ) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),plot.title = element_text(hjust = 0.5),legend.position = "none")

tidy_hypothesis_result_df
```

![](p8105_hw5_zc2610_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

``` r
  ggsave("./plots/Estimated_proportions_and_CIs_for_each_city.pdf",tidy_hypothesis_result_df, width = 8, height = 5)
```

# Problem 3

Create a function to output mu_hat and p.value of a normal distribution
where n =30 and sigma(sd) = 5 arising from t-test

``` r
sim_estimate_pvalue = function(n = 30, mu, sd = 5){
  simulation_data = tibble(
    x = rnorm(n, mean = mu ,sd) #generate data from normal distribution
  )
  simulation_data %>% 
    summarize(
      mu_hat = t.test(x,conf.level = 0.95) %>%
        broom::tidy() %>%
        pull(estimate),
      p_value = t.test(x,conf.level = 0.95) %>%
        broom::tidy() %>%
        pull(p.value)
    )
}
```

Set mu=0, generate 5000 datasets from the model x∼Normal\[μ,σ\] and save
mu_hat and p.value arising from a test of H:μ=0 α=0.05 using a for loop

``` r
output = vector("list",length = 50)
for (i in 1:50){
  output[[i]] = sim_estimate_pvalue(30,0,5)
}
bind_rows(output)
```

    ## # A tibble: 50 × 2
    ##     mu_hat p_value
    ##      <dbl>   <dbl>
    ##  1  0.410   0.625 
    ##  2 -0.632   0.469 
    ##  3  0.767   0.393 
    ##  4 -0.0590  0.944 
    ##  5 -0.654   0.529 
    ##  6 -1.62    0.0137
    ##  7  0.595   0.473 
    ##  8 -1.38    0.196 
    ##  9 -0.261   0.767 
    ## 10  0.494   0.608 
    ## # … with 40 more rows

Repeat the above for mu={1,2,3,4,5,6}

``` r
sim_results = tibble(
  mu = c(1,2,3,4,5,6)
) %>% 
  mutate(
    output_lists = map(.x = mu,~rerun(50,sim_estimate_pvalue(30,.x,5))),
    estimate_df = map(output_lists,bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_df) #expand the tibble list two show the two columns: mu and p_value
```

Create a new variable named conclusion to show whether the null
hypothesis is rejected (since α=0.05, then p_value should be compared
with 0.05 to determine whether the null hypothesis is rejected(when
p_value \< 0.05))

``` r
sim_results = sim_results %>% 
  mutate(
    conclusion = case_when(
      p_value < 0.05 ~ "reject",
      p_value >= 0.05 ~ "fail to reject"
    )
  )
sim_results
```

    ## # A tibble: 300 × 4
    ##       mu mu_hat p_value conclusion    
    ##    <dbl>  <dbl>   <dbl> <chr>         
    ##  1     1  0.440  0.692  fail to reject
    ##  2     1  0.623  0.518  fail to reject
    ##  3     1  1.52   0.0826 fail to reject
    ##  4     1  0.926  0.352  fail to reject
    ##  5     1  1.48   0.134  fail to reject
    ##  6     1  1.78   0.116  fail to reject
    ##  7     1  1.30   0.172  fail to reject
    ##  8     1  1.87   0.0582 fail to reject
    ##  9     1  0.531  0.574  fail to reject
    ## 10     1  1.71   0.0534 fail to reject
    ## # … with 290 more rows

1.  Count the number of total conclusions with each true mu
2.  Count the number of “reject” conclusions with each true mu
3.  Calculate the proportion of times the null was rejected

``` r
sim_results %>% 
  group_by(mu) %>% 
  summarise(
    conclusion_total = n(),
    conclusion_reject = sum(conclusion == "reject")
  ) %>% 
  mutate(
    proportion = conclusion_reject/conclusion_total
  )
```

    ## # A tibble: 6 × 4
    ##      mu conclusion_total conclusion_reject proportion
    ##   <dbl>            <int>             <int>      <dbl>
    ## 1     1               50                 5       0.1 
    ## 2     2               50                28       0.56
    ## 3     3               50                47       0.94
    ## 4     4               50                50       1   
    ## 5     5               50                50       1   
    ## 6     6               50                50       1
